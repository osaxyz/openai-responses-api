# Auto-generated by apps/try collector
# Re-run `npm run collect` to regenerate
schema:
  id: "parameters/temperature"
  description: "temperature指定"
  category: "parameters"
  method: "generateText"
  model_id: "gpt-5.2"
  collected_at: "2026-02-11T02:03:54.476Z"
  sdk_version: "6.0.78"
  provider_version: "3.0.26"
request:
  model: "gpt-5.2"
  input:
    - role: "user"
      content:
        - type: "input_text"
          text: "Write a creative short poem about the moon."
response:
  id: "resp_075f98dd891a331c00698be386066081949d17706c9aa5cb12"
  object: "response"
  created_at: 1770775430
  status: "completed"
  background: false
  billing:
    payer: "developer"
  completed_at: 1770775433
  error: null
  frequency_penalty: 0
  incomplete_details: null
  instructions: null
  max_output_tokens: null
  max_tool_calls: null
  model: "gpt-5.2-2025-12-11"
  output:
    - id: "msg_075f98dd891a331c00698be38667cc8194b27d320569890afb"
      type: "message"
      status: "completed"
      content:
        - type: "output_text"
          annotations: []
          logprobs: []
          text: "The moon hangs like a silver secret, \ 

            Pinned to the dark with quiet light. \ 

            It stitches tides to sleeping shorelines, \ 

            And mends the sky throughout the night. \ 


            It sips the sun’s forgotten honey, \ 

            Then pours it out in pale refrain— \ 

            A lantern for the lost and longing, \ 

            A witness to the windowpane. \ 


            When city noise turns into silence, \ 

            It lifts its face, serene, alone; \ 

            And in its calm, I hear the universe \ 

            Speak softly through a borrowed glow."
      role: "assistant"
  parallel_tool_calls: true
  presence_penalty: 0
  previous_response_id: null
  prompt_cache_key: null
  prompt_cache_retention: null
  reasoning:
    effort: "none"
    summary: null
  safety_identifier: null
  service_tier: "default"
  store: true
  temperature: 1
  text:
    format:
      type: "text"
    verbosity: "medium"
  tool_choice: "auto"
  tools: []
  top_logprobs: 0
  top_p: 0.98
  truncation: "disabled"
  usage:
    input_tokens: 15
    input_tokens_details:
      cached_tokens: 0
    output_tokens: 112
    output_tokens_details:
      reasoning_tokens: 0
    total_tokens: 127
  user: null
  metadata: {}
