# Auto-generated by apps/try collector
# Re-run `npm run collect` to regenerate
schema:
  id: "parameters/max_output_tokens"
  description: "maxOutputTokens指定"
  category: "parameters"
  method: "generateText"
  model_id: "gpt-5.2"
  collected_at: "2026-02-11T02:03:58.500Z"
  sdk_version: "6.0.78"
  provider_version: "3.0.26"
request:
  model: "gpt-5.2"
  input:
    - role: "user"
      content:
        - type: "input_text"
          text: "Explain quantum computing."
  max_output_tokens: 100
response:
  id: "resp_030a983d693e221700698be38ba2c48194af66e1a06f9f5076"
  object: "response"
  created_at: 1770775435
  status: "incomplete"
  background: false
  billing:
    payer: "developer"
  completed_at: null
  error: null
  frequency_penalty: 0
  incomplete_details:
    reason: "max_output_tokens"
  instructions: null
  max_output_tokens: 100
  max_tool_calls: null
  model: "gpt-5.2-2025-12-11"
  output:
    - id: "msg_030a983d693e221700698be38befb88194af21ee1e19c2b15f"
      type: "message"
      status: "incomplete"
      content:
        - type: "output_text"
          annotations: []
          logprobs: []
          text: "Quantum computing is a way of processing information using the rules of quantum mechanics (the physics of very small things). Instead of storing and manipulating data as ordinary bits, it uses **quantum bits (qubits)**, which behave differently and can enable certain computations to be done much faster than on classical computers.


            ## Classical bits vs qubits

            - **Classical bit:** always either **0** or **1**.

            - **Qubit:** can be in a combination of **0"
      role: "assistant"
  parallel_tool_calls: true
  presence_penalty: 0
  previous_response_id: null
  prompt_cache_key: null
  prompt_cache_retention: null
  reasoning:
    effort: "none"
    summary: null
  safety_identifier: null
  service_tier: "default"
  store: true
  temperature: 1
  text:
    format:
      type: "text"
    verbosity: "medium"
  tool_choice: "auto"
  tools: []
  top_logprobs: 0
  top_p: 0.98
  truncation: "disabled"
  usage:
    input_tokens: 10
    input_tokens_details:
      cached_tokens: 0
    output_tokens: 100
    output_tokens_details:
      reasoning_tokens: 0
    total_tokens: 110
  user: null
  metadata: {}
