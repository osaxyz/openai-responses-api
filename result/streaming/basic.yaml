# Auto-generated by apps/try collector
# Re-run `npm run collect` to regenerate
schema:
  id: "streaming/basic"
  description: "基本的なストリーミング"
  category: "streaming"
  method: "streamText"
  model_id: "gpt-5.2"
  collected_at: "2026-02-11T02:02:56.002Z"
  sdk_version: "6.0.78"
  provider_version: "3.0.26"
request:
  model: "gpt-5.2"
  input:
    - role: "user"
      content:
        - type: "input_text"
          text: "Count from 1 to 5."
  stream: true
response:
  stream: true
  events:
    - type: "response.created"
      response:
        id: "resp_0a5c636b9f3143d900698be34f6ed4819092526116371f21c8"
        object: "response"
        created_at: 1770775375
        status: "in_progress"
        background: false
        completed_at: null
        error: null
        frequency_penalty: 0
        incomplete_details: null
        instructions: null
        max_output_tokens: null
        max_tool_calls: null
        model: "gpt-5.2-2025-12-11"
        output: []
        parallel_tool_calls: true
        presence_penalty: 0
        previous_response_id: null
        prompt_cache_key: null
        prompt_cache_retention: null
        reasoning:
          effort: "none"
          summary: null
        safety_identifier: null
        service_tier: "auto"
        store: true
        temperature: 1
        text:
          format:
            type: "text"
          verbosity: "medium"
        tool_choice: "auto"
        tools: []
        top_logprobs: 0
        top_p: 0.98
        truncation: "disabled"
        usage: null
        user: null
        metadata: {}
      sequence_number: 0
    - type: "response.in_progress"
      response:
        id: "resp_0a5c636b9f3143d900698be34f6ed4819092526116371f21c8"
        object: "response"
        created_at: 1770775375
        status: "in_progress"
        background: false
        completed_at: null
        error: null
        frequency_penalty: 0
        incomplete_details: null
        instructions: null
        max_output_tokens: null
        max_tool_calls: null
        model: "gpt-5.2-2025-12-11"
        output: []
        parallel_tool_calls: true
        presence_penalty: 0
        previous_response_id: null
        prompt_cache_key: null
        prompt_cache_retention: null
        reasoning:
          effort: "none"
          summary: null
        safety_identifier: null
        service_tier: "auto"
        store: true
        temperature: 1
        text:
          format:
            type: "text"
          verbosity: "medium"
        tool_choice: "auto"
        tools: []
        top_logprobs: 0
        top_p: 0.98
        truncation: "disabled"
        usage: null
        user: null
        metadata: {}
      sequence_number: 1
    - type: "response.output_item.added"
      item:
        id: "msg_0a5c636b9f3143d900698be34fc03481908943d46771f920ec"
        type: "message"
        status: "in_progress"
        content: []
        role: "assistant"
      output_index: 0
      sequence_number: 2
    - type: "response.content_part.added"
      content_index: 0
      item_id: "msg_0a5c636b9f3143d900698be34fc03481908943d46771f920ec"
      output_index: 0
      part:
        type: "output_text"
        annotations: []
        logprobs: []
        text: ""
      sequence_number: 3
    - type: "response.output_text.delta"
      content_index: 0
      delta: "1"
      item_id: "msg_0a5c636b9f3143d900698be34fc03481908943d46771f920ec"
      logprobs: []
      obfuscation: "rHf8jAZLINKDDCM"
      output_index: 0
      sequence_number: 4
    - type: "response.output_text.delta"
      content_index: 0
      delta: " \ \n"
      item_id: "msg_0a5c636b9f3143d900698be34fc03481908943d46771f920ec"
      logprobs: []
      obfuscation: "tTbMa5Qb9U3Zn"
      output_index: 0
      sequence_number: 5
    - type: "response.output_text.delta"
      content_index: 0
      delta: "2"
      item_id: "msg_0a5c636b9f3143d900698be34fc03481908943d46771f920ec"
      logprobs: []
      obfuscation: "0tttiuSEeedhk8A"
      output_index: 0
      sequence_number: 6
    - type: "response.output_text.delta"
      content_index: 0
      delta: " \ \n"
      item_id: "msg_0a5c636b9f3143d900698be34fc03481908943d46771f920ec"
      logprobs: []
      obfuscation: "pyhtvpGWORE0c"
      output_index: 0
      sequence_number: 7
    - type: "response.output_text.delta"
      content_index: 0
      delta: "3"
      item_id: "msg_0a5c636b9f3143d900698be34fc03481908943d46771f920ec"
      logprobs: []
      obfuscation: "OgOHqkRaxm43pmC"
      output_index: 0
      sequence_number: 8
    - type: "response.output_text.delta"
      content_index: 0
      delta: " \ \n"
      item_id: "msg_0a5c636b9f3143d900698be34fc03481908943d46771f920ec"
      logprobs: []
      obfuscation: "lXKlJH7NQCI0b"
      output_index: 0
      sequence_number: 9
    - type: "response.output_text.delta"
      content_index: 0
      delta: "4"
      item_id: "msg_0a5c636b9f3143d900698be34fc03481908943d46771f920ec"
      logprobs: []
      obfuscation: "nfAQ01fTzs7QZSx"
      output_index: 0
      sequence_number: 10
    - type: "response.output_text.delta"
      content_index: 0
      delta: " \ \n"
      item_id: "msg_0a5c636b9f3143d900698be34fc03481908943d46771f920ec"
      logprobs: []
      obfuscation: "r355v4wWMjcLM"
      output_index: 0
      sequence_number: 11
    - type: "response.output_text.delta"
      content_index: 0
      delta: "5"
      item_id: "msg_0a5c636b9f3143d900698be34fc03481908943d46771f920ec"
      logprobs: []
      obfuscation: "1G3m7MW0RBMDJuP"
      output_index: 0
      sequence_number: 12
    - type: "response.output_text.done"
      content_index: 0
      item_id: "msg_0a5c636b9f3143d900698be34fc03481908943d46771f920ec"
      logprobs: []
      output_index: 0
      sequence_number: 13
      text: "1 \ \n2 \ \n3 \ \n4 \ \n5"
    - type: "response.content_part.done"
      content_index: 0
      item_id: "msg_0a5c636b9f3143d900698be34fc03481908943d46771f920ec"
      output_index: 0
      part:
        type: "output_text"
        annotations: []
        logprobs: []
        text: "1 \ \n2 \ \n3 \ \n4 \ \n5"
      sequence_number: 14
    - type: "response.output_item.done"
      item:
        id: "msg_0a5c636b9f3143d900698be34fc03481908943d46771f920ec"
        type: "message"
        status: "completed"
        content:
          - type: "output_text"
            annotations: []
            logprobs: []
            text: "1 \ \n2 \ \n3 \ \n4 \ \n5"
        role: "assistant"
      output_index: 0
      sequence_number: 15
    - type: "response.completed"
      response:
        id: "resp_0a5c636b9f3143d900698be34f6ed4819092526116371f21c8"
        object: "response"
        created_at: 1770775375
        status: "completed"
        background: false
        completed_at: 1770775375
        error: null
        frequency_penalty: 0
        incomplete_details: null
        instructions: null
        max_output_tokens: null
        max_tool_calls: null
        model: "gpt-5.2-2025-12-11"
        output:
          - id: "msg_0a5c636b9f3143d900698be34fc03481908943d46771f920ec"
            type: "message"
            status: "completed"
            content:
              - type: "output_text"
                annotations: []
                logprobs: []
                text: "1 \ \n2 \ \n3 \ \n4 \ \n5"
            role: "assistant"
        parallel_tool_calls: true
        presence_penalty: 0
        previous_response_id: null
        prompt_cache_key: null
        prompt_cache_retention: null
        reasoning:
          effort: "none"
          summary: null
        safety_identifier: null
        service_tier: "default"
        store: true
        temperature: 1
        text:
          format:
            type: "text"
          verbosity: "medium"
        tool_choice: "auto"
        tools: []
        top_logprobs: 0
        top_p: 0.98
        truncation: "disabled"
        usage:
          input_tokens: 14
          input_tokens_details:
            cached_tokens: 0
          output_tokens: 13
          output_tokens_details:
            reasoning_tokens: 0
          total_tokens: 27
        user: null
        metadata: {}
      sequence_number: 16
